---
title: 'Beginners Social Networks Course: Session 3'
author: "Matthew Silk"
date: "2025-10-20"
output: 
  html_document:
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Set up R environment

First we need to load the R packages we will use. You may need to install these if you haven't used them before using the `install.packages()` command in R. For genNetDem you will need to follow the instructions [here](https://github.com/NETDEM-project/genNetDem) to install it.

```{r packages, warning=FALSE,message=FALSE}

set.seed(1)

library(igraph)
library(asnipe)
library(viridis)
library(assortnet)
library(genNetDem)
library(brms)
library(Matrix)
library(sna)

```

***

In this session we will focus on applying regression approaches to social networks, thinking about some of the issues we need to think about when doing so. Except when we are using specific R packages tailored to social network modelling, I am going to use the R package [brms](https://paul-buerkner.github.io/brms/) for the example analyses here. The reasons for this is that brms provides a fantastic combination of being incredibly flexible and also user friendly perfect for getting to grips with these approaches for the first time. The other reason is that by using Bayesian approaches [handle issues with non-independence more robustly than frequentist approaches](https://www.nature.com/articles/s41598-017-18104-4).

First we need our network data again. 

```{r read_in}

#Read in the network object
full_adj<-readRDS("full_adj.RDS")
#Read in associated trait data
ind_data<-readRDS("ind_data.RDS")
names(ind_data)[1]<-"id"

#Create a weighted version of full_adj - we are adding edge weights from a beta distribution
full_adj_weight<-rbeta(sum(upper.tri(full_adj)),2,7)
full_adj[upper.tri(full_adj)]<-full_adj_weight*full_adj[upper.tri(full_adj)]
full_adj[lower.tri(full_adj)]<-t(full_adj)[lower.tri(full_adj)]

#Create igraph network object
network<-igraph::graph_from_adjacency_matrix(full_adj,mode="undirected",weighted=TRUE)
V(network)$size<-5+ind_data$offspring
V(network)$sex<-ind_data$sex
V(network)$group<-ind_data$group

```


***

## SESSION 3: PART 3

First we are going to start with nodal regressions that involve non-network traits as these are the simplest category of regressions, and largely will be similar to ones that you are used to. The main consideration with these types of nodal regressions is if there is non-independence related to individuals closely connected in the social network being more (or less!) similar than you would expect by chance. If you are confident this is not the case, then you can work with these types of regression analyses in the same you way for any other individual trait. However, if you want to account for the potential dependence between connected individuals, there are a couple of options:

1. You can adapt methods from spatial analyses or quantitative genetics (the [animal model](https://besjournals.onlinelibrary.wiley.com/doi/10.1111/j.1365-2656.2009.01639.x)) and directly use the network as a weighting matrix.

2. You can work with [network autocorrelation models](https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.12770). This allows considerable flexibility in how you model network-related covariance in traits, including the ability to model specific functional relationships and over different neighbourhoods (e.g. first-order vs. second-order connections). But it comes at the cost of subjectivity and decision-making!

We will demonstrate how each approach might work below using the `full_adj` network and `ind_data` data frame. We will test the hypothesis that the weight of individuals is associated with their sex and network centrality.

```{r nr1}

#We start by calculating a network measure and adding it to the dataframe
ind_data$degree<-igraph::degree(network)

##Without covariance issues our regression is simply
model1<-brm(formula=weight~sex+degree,data=ind_data)

#Check model summary
summary(model1)

```

Note that there is no effect of sex or degree centrality in this case - this is unsurprising as I simulated the data independently of each other. Feel free to test your own hypothesis in this dataset or simulate a new variable that is associated with one or more measures of individual network position.

I am also deliberately not focusing too much on either statistical inference or Bayesian model specification. These things are clearly important but extend beyond the remits of *"social network analysis"*. So to save time and focus on the social network methods I am leaving them out for now. When working with networks I typically like to use full model inference or work with a subset of models with clear (potential) causal pathways - network analyses are already complex and it is easy to over-complicate them! There are lots of resources available online related to Bayesian modelling if you are unsure on this topic. You could also adjust many of these models for Frequentist inference too.

***

Now we will introduce the use of covariance matrices to this same regression.

```{r nr2}

##The next option is to use the social network as a covariance matrix
#We first need to convert the social network to be usable as a covariance matrix - it needs to be positive definite to allow this.
weight_matrix<-full_adj
diag(weight_matrix)<-1
#Here we use the nearest positive definite matrix approximated by the function nearPD from the Matrix package
weight_matrix<-as.matrix(Matrix::nearPD(weight_matrix,keepDiag=TRUE)$mat)
#Row and column names need to match our dataset
colnames(weight_matrix)<-rownames(weight_matrix)<-ind_data$id

#We can use a matrix regression approach to test that the approximated matrix is correlated with the social network - more on this statistical method later...
summary(sna::netlm(weight_matrix,full_adj))

#We can then fit our regression using gr() in brms and providing the matrix we calculated as the covariance matrix
model2<-brm(formula=weight~sex+degree+(1|gr(id,cov=weight_matrix)),data=ind_data,data2=list(weight_matrix=weight_matrix),chains=4,cores=4,iter=5000,warmup=1000)

#check model summary
summary(model2)

#Calculate the importance of network covariance
hyp <- "sd_id__Intercept^2 / (sd_id__Intercept^2 + sigma^2) = 0"
hyp <- hypothesis(model2, hyp, class = NULL)
plot(hyp)

```

As above, we find no covariance here (the posterior distribution of `hyp` is very close to zero) because the dataset wasn't simulated this way in the first place. We can also see that the estimated effects of sex and degree are very similar to the first model.

***

The third option is the network autocorrelation modeling framework. I provide a couple of examples here, showing different ways we may introduce covariance structures. With NAMs we are specifying the dependencies between socially connected nodes ourselves.

```{r nr3}

#The first step of our NAM analysis is to calculate two new variables: 1) the mean weight of all immediately adjacency nodes (first-order neighbours); and 2) half the mean weight of all second-order neighbours.

#Work out first-order neighbours
egos1<-igraph::ego(network)

#Work-out second-order neighbours
egos2<-igraph::ego(network,order=2,mindist=2)

#Let's now calculate the variables
ind_data$fo_eff<-ind_data$so_eff<-rep(NA,nrow(ind_data))
#We'll use a loop here as it is easier to follow what is going on
#Note that because the order of individuals in our dataframe matches that in the matrix we can use some coding shortcuts here
#but be careful to make sure these match if you use this type of approach in your own analysis
for(i in 1:nrow(ind_data)){
  ind_data$fo_eff[i]<-mean(ind_data$weight[egos1[[i]]],na.rm=TRUE)
  ind_data$so_eff[i]<-0.5*mean(ind_data$weight[egos2[[i]]],na.rm=TRUE)
}

#First a model with just the effect of first-order neighbours
model3<-brm(formula=weight~sex+degree+fo_eff,data=ind_data)
#Check model summary
summary(model3)

#Now we can add the effect of second-order neighbours
model4<-brm(formula=weight~sex+degree+fo_eff+so_eff,data=ind_data)
#Check model summary
summary(model4)

```

This gives a basic insight into how network autocorrelations models work. The positive effect of the mean weight of first-order neighbours is a surprise - it wasn't simulated into the dataset, and may warrant further investigation. However, it is at odds with our `model2` results. This suggests that if we incorporated edge weights into our calculation of the first-order effect it may disappear. This may be something to try if you are feeling happy with the general idea of how these models work. Note also that we chose that our neighbourhood effects should be weighted by dividing through by path length - this is a common functional form to use in NAMs but you could equally pick something else. In fact, the terms you could include in this general framework are only really limited by your imagination - this subjectivity can be both a strength and a major weakness. Again, a key piece of advice is to keep your models simple and to only include autocorrelation terms that you have clear expectations to have an effect. It can also be useful for distinguish between exploratory analyses where you are looking to describe potentially interesting patterns in the data versus hypothesis testing where you are examining the ability of a pre-conceived model to explain variation in your study system.

Hopefully, these examples give a good grounding in approaches to incorporating social networks in regression-type analyses for non-network traits.

***
***

## SESSION 3: PART 4

That means the next step is to look at how we conduct nodal regressions when network traits (such as degree or other centrality measures) are the response variable. Note that people are moving away from using permutation approaches for these types of analyses and so this is an area that is in flux and the value of the ideas I teach here could change quickly!

Currently, the most sensible approach to nodal regressions is to use Bayesian inference and not worry about using permutation methods. For example, a regression for a centrality measure could look like this:

```{r nr4}

ind_data$strength<-igraph::strength(network)
modelS1<-brm(formula=strength~sex,data=ind_data)
summary(modelS1)

```

One slightly painful aspect of social network measures for nodel regressions is that many of them require non-Gaussian error distributions to model well. To illustrate, our diagnostic plots for our model for strength are just fine, but if we use the same model for betweenness centrality things go wrong...

```{r nr5}

#Posterior predictive check for strength
pp_check(modelS1,ndraws=100)

#Add betweenness as a variable
ind_data$betweenness<-igraph::betweenness(network,weights=1/E(network)$weight)

#Fit same model but for betweenness
modelB1<-brm(formula=betweenness~sex,data=ind_data)

#Posterior predictive check for betweenness
pp_check(modelB1,ndraws=100)

```

Not only does our posterior not match the observed density, but it also predicts betweenness values below zero which isn't possible. In the case of betweenness centrality, this issue can be fixed using both a negative binomial family model and a zero-inflation component.

```{r nr6}

#Fit zero-inflated negative binomial model
modelB2<-brm(bf(betweenness~sex, zi~sex),data=ind_data,family=zero_inflated_negbinomial())

#Posterior predictive check for new model
pp_check(modelB2,ndraws=100)

```

The best model to use will depend on the network measure you are using and also aspects of the social system you are studying. For example, eigenvector centrality and clustering coefficient scale between 0 and 1, while (uncorrected) degree is a count that can only be discrete numbers. In general, you should be able to make a good start with knowledge of the measures and their distributions in your study system and refine from there.

You may want to control for some network dependency using random effect structures, e.g. using social groupings or by using individual-level random effects for repeated or longitudinal data. For example, for our dataset we could use group as a random effect.

```{r nr7}

#Fit zero-inflated negative binomial model
modelB3<-brm(bf(betweenness~sex+(1|group), zi~sex+(1|group)),data=ind_data,family=zero_inflated_negbinomial())
#Look at model summary
summary(modelB3)

```

However, there is an important caveat here. It might be tempting to use features of the network - such as social grouping you detect using community detection algorithms. But there is a technical issue here, which is that your network measure and the social communities both depend on the same set of social observations meaning that they weren't measured independently of each other. This violates assumptions of the model fitting process meaning that approaches like this are best avoided.

One thing that I won't cover here, but is important to think about is also including the observation process in your model and propagating any uncertainty through to any subsequent regression analyses (note that this could also apply to Part 3 above). Currently, the best guidance to taking this approach for animal social networks is available [here](https://www.biorxiv.org/content/10.1101/2021.12.20.473541v2.full). Taking this type of approach makes it easier to control for variation in sampling effort between individuals or regions of the network, for example. It could also be possible to control for these directly when modelling social network measure by including them as a covariate - although note here that for some measures in particular you might expect these relationships to be non-linear favouring using GAMs or specifying the form of the relationship (see [here]() for more detail about this approach).

***
***

## SESSION 3: PART 5

Now we have covered some examples of nodal regressions, it is time to think instead about analyses focused directly on the edges of the network or the network object. These can also be invaluable for testing hypotheses related to the structure of animal social networks.

***

The first useful dyadic regression to know are matrix regression approaches adapted for social networks. These can be run using `netlm` in the R package [sna](https://cran.r-project.org/web/packages/sna/sna.pdf). These approaches are effective for testing the association between social networks for different types of behaviours or for testing the association between social networks and other types of matrix such as home range overlap or distance matrices for spatial analysis, or a relatedness matrix to test how well genetic relationships explain social relationships.

We first will use this approach to compare the `full_adj` network with a network of grouping events generated using the R package `genNetDem` immediately below. We therefore predict a strong positive relationship between these two matrices. `netlm` uses a permutation approach, and you can specify the one you use using the `nullhyp` argument. In general, I would recommend using `qapspp` as a starting point, but it is helpful to familiarise yourself with the other options.

```{r generate_gbi}

#Note we need to slightly change the format of our ind_data object here to suit the package
t_ind_data<-ind_data[,1:5]
names(t_ind_data)[1]<-"indivs"

#We can then use the interaction_generation_simul function to generate groups based on our network
groupings<-genNetDem::interaction_generation_simul(indiv_data=t_ind_data,pop_mat=full_adj,mean_group_size=3,n_ts=20)

#We can create a network using this group-by-individual matrix and plot it to see what it looks like
group_mat<-asnipe::get_network(groupings[[1]])
group_net<-igraph::graph_from_adjacency_matrix(group_mat,mode="undirected",weighted=TRUE)

plot(group_net,vertex.size=15,vertex.color="gray10",vertex.label.color="white",vertex.label.cex=0.75)

#We also have information available on the times that groupiing events were observed at
day<-groupings[[2]]
day

diag(group_mat)<-NA

```

Now we fit the network regression.

```{r mrqap1}

#Fit model - we keep reps lower here but you may want to increase it for a formal analysis
net_model1<-sna::netlm(y=group_mat,x=full_adj,nullhyp="qapspp",reps=1000)

#Examine model summary
summary(net_model1)

```

The relationship between the two networks is as we would expect. The useful thing about `netlm` is we can use it to have multiple networks or matrices as explanatory variables to test what explains social network structure best. Below we simulate two matrices for home range overlap and relatedness to demonstrate how to implement this.

```{r mrqap2}

#Simulate our matrices of home range overlap and relatedness
hr_overlap<-relatedness<-matrix(0,nr=100,nc=100)
for (i in 1:(ncol(relatedness)-1)){
  for(j in (i+1):ncol(relatedness)){
    relatedness[i,j]<-relatedness[j,i]<-sample(c(0.5,0.25,runif(1,min=-0.1,max=0.25)),1,prob=c(0.02,0.08,0.9))
    hr_overlap[i,j]<-hr_overlap[j,i]<-ifelse(ind_data$group[i]==ind_data$group[j],runif(1,min=0.6,max=0.9),runif(1,min=0.1,max=0.65))
  }
}

#Fit model - we keep reps lower here but you may want to increase it for a formal analysis
net_model2<-sna::netlm(y=group_mat,x=list(hr_overlap,relatedness),nullhyp="qapspp",reps=1000)

#Examine model summary
summary(net_model2)

```

With this second analysis we explain ~25% of variation in our data, with home range overlap having a statistically clear association with social network structure (the weight of edges). Take a look at how the data were simulated and see if you can work out why home range overlap is associated with social structure but home range overlap isn't.

***

`netlm` can only get us so far with dyadic regressions. A more sophisticated approach that allows us to incorporate a greater range of explanatory variables uses what are known as multiple membership random effects. Multiple membership random effects allow us to estimate the variation attributable to particular individuals or nodes when we only have data on dyadic relationships (each of which consists of two individuals or nodes). Fortunately, **brms** (and various other R packages) make fitting these models relatively straightforward. We demonstrate an example below using our `full_adj` network.

We will test two hypotheses - that edge strength is influenced by a) social group membership; and b) whether the dyads are female-female, female-male or male-male.

```{r multiplemembership}

#First we need to make an edge list which is equivalent to long-form data for dyadic regressions
#Make empty edgelist
el_network<-matrix(NA,nr=0.5*(nrow(full_adj)^2-nrow(full_adj)),nc=3)
#Fill edgelist (there are some shortcuts used here because our matrix rows/columns have the same names as our individuals - be careful when using this code)
count<-1
for(i in 1:(ncol(full_adj)-1)){
  for(j in (i+1):ncol(full_adj)){
    el_network[count,1]<-i
    el_network[count,2]<-j
    el_network[count,3]<-full_adj[i,j]
    count<-count+1
  }
}
el_network<-as.data.frame(el_network)
names(el_network)<-c("id1","id2","weight")

#Then we need to calculate our new explanatory variables - we do this as a loop to help display the logic
el_network$same_group<-el_network$dyad_sex<-rep(NA,nrow(el_network))
for(i in 1:nrow(el_network)){
  ifelse(ind_data$group[ind_data$id==el_network$id1[i]]==ind_data$group[ind_data$id==el_network$id2[i]],
  el_network$same_group[i]<-1,
  el_network$same_group[i]<-0)
  el_network$dyad_sex[i]<-paste0(ind_data$sex[ind_data$id==el_network$id1[i]],ind_data$sex[ind_data$id==el_network$id2[i]])
}
#Swap MF to also be FM
el_network$dyad_sex[el_network$dyad_sex=="MF"]<-"FM"

#Make dyad_sex a factor
el_network$dyad_sex<-as.factor(el_network$dyad_sex)

#We can then fit the model
mm_model1<-brm(bf(weight~same_group+dyad_sex+(1|mm(id1,id2)),zi~same_group+dyad_sex+(1|mm(id1,id2))),data=el_network,family=zero_inflated_beta(),chains=4,cores=4)

#Look at the summary
summary(mm_model1)

#And look at the posterior predictive check
pp_check(mm_model1,ndraws=100)

```

The model finds that dyad_sex is not an important variable in explaining our network structure. It does find a really big effect of whether two individuals were in the same group or not, but only in the zero-inflation part of the model.

Here we've just covered the basics of how you might analyses the outputs of social network analyses. If you are interested in finding out more then let me know and I can point you in the right direction.

***
***
***